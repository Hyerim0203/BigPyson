{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 외부데이터 추가한 train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_excel('./data/train.xlsx')\n",
    "train = train[train['판매단가'] < train['취급액']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.index = np.arange(7513)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['노출(분)'] = train['노출(분)'].replace(0, math.nan)\n",
    "train['노출(분)'] = train['노출(분)'].fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_excel('./test.xlsx', header=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 판매단가 log 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['new판매단가'] = np.log(train['판매단가'])\n",
    "train.drop('판매단가', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 주문량 log 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['new주문량'] = np.log(train['주문량'])\n",
    "train.drop('주문량', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 시간대"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = train.groupby('HOUR').aggregate(np.mean)\n",
    "\n",
    "time_rank = {}\n",
    "rank = 1 \n",
    "for idx, row in time.sort_values(by='new주문량').iterrows():\n",
    "    time_rank[idx] = rank\n",
    "    rank += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "prime_time = []\n",
    "\n",
    "for idx, row in train.iterrows():\n",
    "    prime_time.append(time_rank[row.HOUR])\n",
    "    \n",
    "train['prime_time'] = prime_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 요일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "day = train.groupby('요일').aggregate(np.mean)\n",
    "\n",
    "day_rank = {}\n",
    "rank = 1 \n",
    "for idx, row in day.sort_values(by='new주문량').iterrows():\n",
    "    day_rank[idx] = rank\n",
    "    rank += 1\n",
    "    \n",
    "prime_day = []\n",
    "\n",
    "for idx, row in train.iterrows():\n",
    "    prime_day.append(day_rank[row.요일])\n",
    "    \n",
    "train['prime_day'] = prime_day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- test랑 겹치는 마더코드 기준 : 노출시간 대비보다 좋음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "intercode = set(test['마더코드'].unique()).intersection(set(train['마더코드'].unique()))\n",
    "interitem = train[train['마더코드'].isin(intercode)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = interitem.groupby('마더코드').aggregate(np.mean)\n",
    "\n",
    "code_rank = {}\n",
    "rank = 1\n",
    "for idx, row in code.sort_values(by='new주문량').iterrows():\n",
    "    code_rank[idx] = rank\n",
    "    rank += 1\n",
    "\n",
    "top_code = []\n",
    "\n",
    "for idx, row in train.iterrows():\n",
    "    if row.마더코드 in code_rank.keys():\n",
    "        top_code.append(code_rank[row.마더코드])\n",
    "    else:\n",
    "        top_code.append(0)\n",
    "        \n",
    "train['top_code'] = top_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 분류 기준 topcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = train.groupby('분류').aggregate(np.mean)\n",
    "\n",
    "cat_rank = {}\n",
    "rank = 1\n",
    "for idx, row in cat.sort_values(by='new주문량').iterrows():\n",
    "    cat_rank[idx] = rank\n",
    "    rank += 1\n",
    "\n",
    "top_cat = []\n",
    "\n",
    "for idx, row in train.iterrows():\n",
    "    top_cat.append(cat_rank[row.분류])\n",
    "    \n",
    "train['top_cat'] = top_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 분류 변수 원핫/pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc1 = OneHotEncoder()\n",
    "category = np.array(train['분류'])\n",
    "category = category.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "enc1.fit(category)\n",
    "category_ = enc1.transform(category).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "res = pca.fit_transform(category_)\n",
    "res = pd.DataFrame(res, columns=['x1_cat','x2_cat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['x1_cat'] = res['x1_cat']\n",
    "train['x2_cat'] = res['x2_cat']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 실제 날씨(서울)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "real = train.groupby('실제_서울_날씨').aggregate(np.mean)\n",
    "\n",
    "real_rank = {}\n",
    "rank = 1\n",
    "for idx, row in real.sort_values(by='new주문량').iterrows():\n",
    "    real_rank[idx] = rank\n",
    "    rank += 1\n",
    "\n",
    "top_real_weather = []\n",
    "\n",
    "for idx, row in train.iterrows():\n",
    "    top_real_weather.append(real_rank[row.실제_서울_날씨])\n",
    "    \n",
    "train['top_real_weather'] = top_real_weather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 실제 날씨 통합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_total_weather = pd.read_excel('./data/날씨통합.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['실제_최고기온'] = real_total_weather['최고기온']\n",
    "train['실제_최저기온'] = real_total_weather['최저기온']\n",
    "train['실제_강수량'] = real_total_weather['강수량']\n",
    "train['실제_평균풍속'] = real_total_weather['평균풍속']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- train 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>방송일시</th>\n",
       "      <th>노출(분)</th>\n",
       "      <th>마더코드</th>\n",
       "      <th>상품코드</th>\n",
       "      <th>상품명</th>\n",
       "      <th>상품군</th>\n",
       "      <th>취급액</th>\n",
       "      <th>날짜</th>\n",
       "      <th>시간</th>\n",
       "      <th>...</th>\n",
       "      <th>prime_day</th>\n",
       "      <th>top_code</th>\n",
       "      <th>top_cat</th>\n",
       "      <th>x1_cat</th>\n",
       "      <th>x2_cat</th>\n",
       "      <th>top_real_weather</th>\n",
       "      <th>실제_최고기온</th>\n",
       "      <th>실제_최저기온</th>\n",
       "      <th>실제_강수량</th>\n",
       "      <th>실제_평균풍속</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17373</td>\n",
       "      <td>2019-06-15 00:00:00</td>\n",
       "      <td>20.0</td>\n",
       "      <td>100305</td>\n",
       "      <td>200981</td>\n",
       "      <td>오모떼 미라클쉐이핑 브라팬티 시즌3</td>\n",
       "      <td>inner</td>\n",
       "      <td>16517000</td>\n",
       "      <td>2019-06-15</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>-0.006718</td>\n",
       "      <td>0.009977</td>\n",
       "      <td>1</td>\n",
       "      <td>27.266667</td>\n",
       "      <td>16.766667</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17374</td>\n",
       "      <td>2019-06-15 00:20:00</td>\n",
       "      <td>20.0</td>\n",
       "      <td>100305</td>\n",
       "      <td>200981</td>\n",
       "      <td>오모떼 미라클쉐이핑 브라팬티 시즌3</td>\n",
       "      <td>inner</td>\n",
       "      <td>44829000</td>\n",
       "      <td>2019-06-15</td>\n",
       "      <td>00:20:00</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>-0.006718</td>\n",
       "      <td>0.009977</td>\n",
       "      <td>1</td>\n",
       "      <td>27.266667</td>\n",
       "      <td>16.766667</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17375</td>\n",
       "      <td>2019-06-15 00:40:00</td>\n",
       "      <td>20.0</td>\n",
       "      <td>100305</td>\n",
       "      <td>200981</td>\n",
       "      <td>오모떼 미라클쉐이핑 브라팬티 시즌3</td>\n",
       "      <td>inner</td>\n",
       "      <td>56057000</td>\n",
       "      <td>2019-06-15</td>\n",
       "      <td>00:40:00</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>-0.006718</td>\n",
       "      <td>0.009977</td>\n",
       "      <td>1</td>\n",
       "      <td>27.266667</td>\n",
       "      <td>16.766667</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17376</td>\n",
       "      <td>2019-06-15 01:00:00</td>\n",
       "      <td>30.0</td>\n",
       "      <td>100374</td>\n",
       "      <td>201202</td>\n",
       "      <td>USPA  남성 폴로셔츠 위켄드 컬렉션 3종</td>\n",
       "      <td>cloth</td>\n",
       "      <td>9996000</td>\n",
       "      <td>2019-06-15</td>\n",
       "      <td>01:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>-0.076890</td>\n",
       "      <td>0.135790</td>\n",
       "      <td>1</td>\n",
       "      <td>27.266667</td>\n",
       "      <td>16.766667</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17377</td>\n",
       "      <td>2019-06-15 01:00:00</td>\n",
       "      <td>30.0</td>\n",
       "      <td>100374</td>\n",
       "      <td>201206</td>\n",
       "      <td>USPA  여성 폴로셔츠 위켄드 컬렉션 3종</td>\n",
       "      <td>cloth</td>\n",
       "      <td>9409000</td>\n",
       "      <td>2019-06-15</td>\n",
       "      <td>01:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>-0.076890</td>\n",
       "      <td>0.135790</td>\n",
       "      <td>1</td>\n",
       "      <td>27.266667</td>\n",
       "      <td>16.766667</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                방송일시  노출(분)    마더코드    상품코드  \\\n",
       "0       17373 2019-06-15 00:00:00   20.0  100305  200981   \n",
       "1       17374 2019-06-15 00:20:00   20.0  100305  200981   \n",
       "2       17375 2019-06-15 00:40:00   20.0  100305  200981   \n",
       "3       17376 2019-06-15 01:00:00   30.0  100374  201202   \n",
       "4       17377 2019-06-15 01:00:00   30.0  100374  201206   \n",
       "\n",
       "                        상품명    상품군       취급액         날짜        시간  ...  \\\n",
       "0       오모떼 미라클쉐이핑 브라팬티 시즌3  inner  16517000 2019-06-15  00:00:00  ...   \n",
       "1       오모떼 미라클쉐이핑 브라팬티 시즌3  inner  44829000 2019-06-15  00:20:00  ...   \n",
       "2       오모떼 미라클쉐이핑 브라팬티 시즌3  inner  56057000 2019-06-15  00:40:00  ...   \n",
       "3  USPA  남성 폴로셔츠 위켄드 컬렉션 3종  cloth   9996000 2019-06-15  01:00:00  ...   \n",
       "4  USPA  여성 폴로셔츠 위켄드 컬렉션 3종  cloth   9409000 2019-06-15  01:00:00  ...   \n",
       "\n",
       "   prime_day  top_code  top_cat    x1_cat    x2_cat  top_real_weather  \\\n",
       "0          1         0       45 -0.006718  0.009977                 1   \n",
       "1          1         0       45 -0.006718  0.009977                 1   \n",
       "2          1         0       45 -0.006718  0.009977                 1   \n",
       "3          1         0       32 -0.076890  0.135790                 1   \n",
       "4          1         0       32 -0.076890  0.135790                 1   \n",
       "\n",
       "     실제_최고기온    실제_최저기온  실제_강수량 실제_평균풍속  \n",
       "0  27.266667  16.766667     0.8     2.2  \n",
       "1  27.266667  16.766667     0.8     2.2  \n",
       "2  27.266667  16.766667     0.8     2.2  \n",
       "3  27.266667  16.766667     0.8     2.2  \n",
       "4  27.266667  16.766667     0.8     2.2  \n",
       "\n",
       "[5 rows x 69 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 변수 통합"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) 빈도수 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 빈도수인코딩(위의 원핫+pca와 비교해보기)\n",
    "def add_frequency_encoding(data,column): \n",
    "    #데이터프레임,열을 받아서 빈도수인코딩열을 추가해줌\n",
    "    enc_nom = (data.groupby(column).size())/len(data)\n",
    "    data['freq_encode_{}'.format(column)] = data[column].apply(lambda x:enc_nom[x])\n",
    "    print(\"freq_encode column was added\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "freq_encode column was added\n"
     ]
    }
   ],
   "source": [
    "add_frequency_encoding(train,'분류')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) 모든 카테고리에 대해 변수 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모든 카테고리에 대해 따로따로 자동 변수생성\n",
    "category_list = train['상품군'].unique().tolist()\n",
    "for i in category_list:\n",
    "    #카테고리에 해당하는 주문량제외 train데이터 할당   -> 주문량 포함되어있음\n",
    "    globals()['x_{}'.format(i)] = train.loc[train['상품군']==i] \n",
    "    #카테고리에 해당하는 train의 주문량을 할당\n",
    "    globals()['y_{}'.format(i)] = train['new주문량'].loc[train['상품군']==i] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) 카테고리별로 x_train_카테고리 , x_test_카테고리, y_train_카테고리, y_test_카테고리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "for i in category_list:\n",
    "    x_for_split = globals()['x_{}'.format(i)]\n",
    "    y_for_split = globals()['y_{}'.format(i)]\n",
    "    globals()['x_train_{}'.format(i)], globals()['x_test_{}'.format(i)], globals()['y_train_{}'.format(i)], globals()['y_test_{}'.format(i)] = train_test_split(x_for_split, y_for_split, test_size=0.33, random_state=1234)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) 카테고리별 20분 단위 3갈 각각 피팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "catlist = train['상품군'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "#그룹내 방송행간의 시간차이(날짜-날짜) <= 해당그룹 최대 노출(분)인가? \n",
    "# 검토해서 분리하는 함수\n",
    "\n",
    "def split_shoprow(df, time): \n",
    "    shoprow1 = pd.DataFrame()  # train\n",
    "    shoprow2 = pd.DataFrame()  # validation \n",
    "    size = len(df)\n",
    "\n",
    "    for i in range((size)-1):       \n",
    "        if (df['방송일시'].iloc[i+1]-df['방송일시'].iloc[i] <= time):\n",
    "            shoprow1 = shoprow1.append(df.iloc[i])\n",
    "        else:\n",
    "            shoprow2 = shoprow2.append(df.iloc[i])    \n",
    "    i += 1\n",
    "    shoprow2 = shoprow2.append(df.iloc[i])\n",
    "            \n",
    "    return shoprow1,shoprow2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 실험"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175   2019-06-16 15:00:00\n",
      "176   2019-06-16 15:20:00\n",
      "306   2019-06-17 22:00:00\n",
      "307   2019-06-17 22:20:00\n",
      "339   2019-06-18 12:00:00\n",
      "340   2019-06-18 12:20:00\n",
      "466   2019-06-19 22:00:00\n",
      "467   2019-06-19 22:20:00\n",
      "567   2019-06-20 23:00:00\n",
      "568   2019-06-20 23:20:00\n",
      "730   2019-06-22 23:20:00\n",
      "731   2019-06-22 23:40:00\n",
      "761   2019-06-23 11:00:00\n",
      "762   2019-06-23 11:20:00\n",
      "915   2019-06-24 22:00:00\n",
      "Name: 방송일시, dtype: datetime64[ns]\n",
      "177    2019-06-16 15:40:00\n",
      "308    2019-06-17 22:40:00\n",
      "341    2019-06-18 12:40:00\n",
      "468    2019-06-19 22:40:00\n",
      "569    2019-06-20 23:40:00\n",
      "732    2019-06-23 00:00:00\n",
      "763    2019-06-23 11:40:00\n",
      "917    2019-06-24 22:40:00\n",
      "950    2019-06-25 12:40:00\n",
      "1143   2019-06-27 15:40:00\n",
      "Name: 방송일시, dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "#기준시간. 방송끼리 이만큼 붙어있어야 같은 제품의 판매임.\n",
    "criteria_time = pd.Timedelta('0 days 00:{}:00'.format(20))\n",
    "# 3개를 기준으로, 방송타임 2개는 bigfold에 1개는smallfold에 넣겠다.\n",
    "train_big_fold = pd.DataFrame()\n",
    "train_small_fold = pd.DataFrame()\n",
    "# 마더코드 100080에 실험\n",
    "x1 = train[train['마더코드']==100080]\n",
    "train_big_fold, train_small_fold = split_shoprow(x1,criteria_time) \n",
    "# 제대로 나옴\n",
    "print(train_big_fold.head(15)['방송일시'])\n",
    "print(train_small_fold.head(10)['방송일시'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- reindex(할필요없을듯)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat in catlist:\n",
    "    globals()['x_{}'.format(cat)].index = np.arange(len(globals()['x_{}'.format(cat)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 카테고리별로 split 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat in catlist:\n",
    "    selec_cat = globals()['x_{}'.format(cat)]\n",
    "    momcode_cat = selec_cat['마더코드'].unique()\n",
    "    # 걍 한 카테고리에서 가장 노출시간이 긴 시간을 기준으로 해도 될듯?\n",
    "    # 20분씩\n",
    "    max_time = selec_cat['노출(분)'].max()\n",
    "    criteria_time = pd.Timedelta('0 days 00:{}:00'.format(int(max_time)))\n",
    "    T = pd.DataFrame()\n",
    "    V = pd.DataFrame()\n",
    "    \n",
    "    for momcode in momcode_cat:\n",
    "        mom = train[train['마더코드']==momcode]\n",
    "        t, v = split_shoprow(mom, criteria_time) \n",
    "        T = T.append(t)\n",
    "        V = V.append(v)\n",
    "    \n",
    "    globals()['{}_bigfold'.format(cat)] = T\n",
    "    globals()['{}_smallfold'.format(cat)] = V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model 1) rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(beauty_bigfold, y_beauty)\n",
    "predictions = rf.predict(shop_train_x_beauty)\n",
    "mape = mean_absolute_percentage_error(y_train_beauty, predictions)\n",
    "mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model 2) dnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>노출(분)</th>\n",
       "      <th>holiday(includeSS)</th>\n",
       "      <th>실제_서울_최고기온</th>\n",
       "      <th>실제_서울_최저기온</th>\n",
       "      <th>실제_서울_강수량(mm)</th>\n",
       "      <th>실제_수원_최고기온</th>\n",
       "      <th>실제_수원_최저기온</th>\n",
       "      <th>실제_수원_강수량(mm)</th>\n",
       "      <th>실제_파주_최고기온</th>\n",
       "      <th>실제_파주_최저기온</th>\n",
       "      <th>...</th>\n",
       "      <th>예보_수원_강수량</th>\n",
       "      <th>예보_수원_일최고기온</th>\n",
       "      <th>예보_수원_일최저기온</th>\n",
       "      <th>new판매단가</th>\n",
       "      <th>prime_time</th>\n",
       "      <th>prime_day</th>\n",
       "      <th>top_code</th>\n",
       "      <th>top_cat</th>\n",
       "      <th>x1_cat</th>\n",
       "      <th>x2_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5033.000000</td>\n",
       "      <td>5033.000000</td>\n",
       "      <td>5033.000000</td>\n",
       "      <td>5033.000000</td>\n",
       "      <td>5033.000000</td>\n",
       "      <td>5033.000000</td>\n",
       "      <td>5033.000000</td>\n",
       "      <td>5033.000000</td>\n",
       "      <td>5033.000000</td>\n",
       "      <td>5033.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5033.000000</td>\n",
       "      <td>5033.000000</td>\n",
       "      <td>5033.000000</td>\n",
       "      <td>5033.000000</td>\n",
       "      <td>5033.000000</td>\n",
       "      <td>5033.000000</td>\n",
       "      <td>5033.000000</td>\n",
       "      <td>5033.000000</td>\n",
       "      <td>5033.000000</td>\n",
       "      <td>5033.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>20.546592</td>\n",
       "      <td>0.317504</td>\n",
       "      <td>30.417803</td>\n",
       "      <td>22.363501</td>\n",
       "      <td>4.956408</td>\n",
       "      <td>30.430836</td>\n",
       "      <td>21.849235</td>\n",
       "      <td>3.882277</td>\n",
       "      <td>29.281860</td>\n",
       "      <td>19.972601</td>\n",
       "      <td>...</td>\n",
       "      <td>2.902976</td>\n",
       "      <td>30.328116</td>\n",
       "      <td>22.036016</td>\n",
       "      <td>11.898127</td>\n",
       "      <td>9.241009</td>\n",
       "      <td>3.908007</td>\n",
       "      <td>10.049672</td>\n",
       "      <td>32.028412</td>\n",
       "      <td>0.002350</td>\n",
       "      <td>0.001141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.596703</td>\n",
       "      <td>0.465552</td>\n",
       "      <td>2.969046</td>\n",
       "      <td>2.591747</td>\n",
       "      <td>12.336896</td>\n",
       "      <td>2.790699</td>\n",
       "      <td>2.806643</td>\n",
       "      <td>13.206496</td>\n",
       "      <td>2.808008</td>\n",
       "      <td>2.950269</td>\n",
       "      <td>...</td>\n",
       "      <td>5.370899</td>\n",
       "      <td>2.209398</td>\n",
       "      <td>2.602339</td>\n",
       "      <td>1.309688</td>\n",
       "      <td>5.875745</td>\n",
       "      <td>1.993451</td>\n",
       "      <td>17.080805</td>\n",
       "      <td>23.656923</td>\n",
       "      <td>0.250410</td>\n",
       "      <td>0.246119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.800000</td>\n",
       "      <td>16.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.200000</td>\n",
       "      <td>15.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.300000</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.263158</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>9.457200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.509676</td>\n",
       "      <td>-0.669941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.200000</td>\n",
       "      <td>20.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>19.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.500000</td>\n",
       "      <td>17.800000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.131579</td>\n",
       "      <td>28.631579</td>\n",
       "      <td>20.312500</td>\n",
       "      <td>10.913269</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>-0.011886</td>\n",
       "      <td>0.005879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.100000</td>\n",
       "      <td>22.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.200000</td>\n",
       "      <td>21.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.100000</td>\n",
       "      <td>19.900000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>29.947368</td>\n",
       "      <td>21.500000</td>\n",
       "      <td>11.502875</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>-0.006265</td>\n",
       "      <td>0.007684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>32.500000</td>\n",
       "      <td>24.600000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>32.200000</td>\n",
       "      <td>24.600000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>31.200000</td>\n",
       "      <td>23.100000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.973684</td>\n",
       "      <td>31.789474</td>\n",
       "      <td>24.937500</td>\n",
       "      <td>12.992255</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>-0.004896</td>\n",
       "      <td>0.012942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>36.800000</td>\n",
       "      <td>27.900000</td>\n",
       "      <td>62.300000</td>\n",
       "      <td>36.500000</td>\n",
       "      <td>27.900000</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>34.700000</td>\n",
       "      <td>24.700000</td>\n",
       "      <td>...</td>\n",
       "      <td>30.789474</td>\n",
       "      <td>35.894737</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>15.110238</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>0.837735</td>\n",
       "      <td>0.684854</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             노출(분)  holiday(includeSS)   실제_서울_최고기온   실제_서울_최저기온  \\\n",
       "count  5033.000000         5033.000000  5033.000000  5033.000000   \n",
       "mean     20.546592            0.317504    30.417803    22.363501   \n",
       "std       3.596703            0.465552     2.969046     2.591747   \n",
       "min       5.000000            0.000000    24.800000    16.100000   \n",
       "25%      20.000000            0.000000    28.200000    20.200000   \n",
       "50%      20.000000            0.000000    30.100000    22.300000   \n",
       "75%      20.000000            1.000000    32.500000    24.600000   \n",
       "max      30.000000            1.000000    36.800000    27.900000   \n",
       "\n",
       "       실제_서울_강수량(mm)   실제_수원_최고기온   실제_수원_최저기온  실제_수원_강수량(mm)   실제_파주_최고기온  \\\n",
       "count    5033.000000  5033.000000  5033.000000    5033.000000  5033.000000   \n",
       "mean        4.956408    30.430836    21.849235       3.882277    29.281860   \n",
       "std        12.336896     2.790699     2.806643      13.206496     2.808008   \n",
       "min         0.000000    25.200000    15.300000       0.000000    22.300000   \n",
       "25%         0.000000    28.000000    19.700000       0.000000    27.500000   \n",
       "50%         0.000000    30.200000    21.500000       0.000000    29.100000   \n",
       "75%         2.900000    32.200000    24.600000       1.000000    31.200000   \n",
       "max        62.300000    36.500000    27.900000     108.000000    34.700000   \n",
       "\n",
       "        실제_파주_최저기온  ...    예보_수원_강수량  예보_수원_일최고기온  예보_수원_일최저기온      new판매단가  \\\n",
       "count  5033.000000  ...  5033.000000  5033.000000  5033.000000  5033.000000   \n",
       "mean     19.972601  ...     2.902976    30.328116    22.036016    11.898127   \n",
       "std       2.950269  ...     5.370899     2.209398     2.602339     1.309688   \n",
       "min      13.500000  ...     0.000000    26.263158    16.000000     9.457200   \n",
       "25%      17.800000  ...     0.131579    28.631579    20.312500    10.913269   \n",
       "50%      19.900000  ...     1.250000    29.947368    21.500000    11.502875   \n",
       "75%      23.100000  ...     2.973684    31.789474    24.937500    12.992255   \n",
       "max      24.700000  ...    30.789474    35.894737    26.000000    15.110238   \n",
       "\n",
       "        prime_time    prime_day     top_code      top_cat       x1_cat  \\\n",
       "count  5033.000000  5033.000000  5033.000000  5033.000000  5033.000000   \n",
       "mean      9.241009     3.908007    10.049672    32.028412     0.002350   \n",
       "std       5.875745     1.993451    17.080805    23.656923     0.250410   \n",
       "min       1.000000     1.000000     0.000000     1.000000    -0.509676   \n",
       "25%       4.000000     2.000000     0.000000    11.000000    -0.011886   \n",
       "50%       9.000000     4.000000     0.000000    27.000000    -0.006265   \n",
       "75%      14.000000     6.000000    12.000000    50.000000    -0.004896   \n",
       "max      20.000000     7.000000    64.000000    83.000000     0.837735   \n",
       "\n",
       "            x2_cat  \n",
       "count  5033.000000  \n",
       "mean      0.001141  \n",
       "std       0.246119  \n",
       "min      -0.669941  \n",
       "25%       0.005879  \n",
       "50%       0.007684  \n",
       "75%       0.012942  \n",
       "max       0.684854  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_col = ['실제_서울_최고기온', '실제_서울_최저기온', '실제_서울_강수량(mm)', \n",
    "           '실제_수원_최고기온', '실제_수원_최저기온', '실제_수원_강수량(mm)',\n",
    "           '실제_파주_최고기온', '실제_파주_최저기온', '실제_파주_강수량(mm)', \n",
    "           '예보_서울_강수확률', '예보_서울_강수량', '예보_서울_하늘상태', \n",
    "           '예보_서울_일최고기온', '예보_서울_일최저기온', '예보_일산_강수확률', \n",
    "           '예보_일산_강수량', '예보_일산_일최고기온', '예보_일산_일최저기온', \n",
    "           '예보_수원_강수확률', '예보_수원_강수량', '예보_수원_일최고기온',\n",
    "           '예보_수원_일최저기온', 'new판매단가']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KSE\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\KSE\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:965: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\KSE\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\KSE\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:965: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "x_train_1[reg_col] = scaler.fit_transform((x_train_1[reg_col]))\n",
    "x_val_1[reg_col] = scaler.fit_transform((x_val_1[reg_col]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = 31\n",
    "n_h1 = 50\n",
    "n_h2 = 50\n",
    "n_outputs = 1\n",
    "\n",
    "#### optimizer = sgd\n",
    "\n",
    "m1 = Sequential()\n",
    "m1.add(Dense(n_h1, input_dim=31, kernel_initializer='normal', activation='relu'))\n",
    "m1.add(Dense(n_h2, input_dim=n_h1, kernel_initializer='normal', activation='relu'))\n",
    "m1.add(Dense(n_outputs, input_dim=n_h2, kernel_initializer='normal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "252/252 [==============================] - 0s 2ms/step - loss: 0.8259\n",
      "Epoch 2/20\n",
      "252/252 [==============================] - 0s 2ms/step - loss: 0.7816\n",
      "Epoch 3/20\n",
      "252/252 [==============================] - 1s 3ms/step - loss: 0.7413\n",
      "Epoch 4/20\n",
      "252/252 [==============================] - 1s 2ms/step - loss: 0.7179\n",
      "Epoch 5/20\n",
      "252/252 [==============================] - 1s 2ms/step - loss: 0.6937\n",
      "Epoch 6/20\n",
      "252/252 [==============================] - 1s 2ms/step - loss: 0.6754\n",
      "Epoch 7/20\n",
      "252/252 [==============================] - 1s 2ms/step - loss: 0.6599\n",
      "Epoch 8/20\n",
      "252/252 [==============================] - 0s 2ms/step - loss: 0.6683\n",
      "Epoch 9/20\n",
      "252/252 [==============================] - 1s 3ms/step - loss: 0.6430\n",
      "Epoch 10/20\n",
      "252/252 [==============================] - 1s 3ms/step - loss: 0.6387A: 0s - l\n",
      "Epoch 11/20\n",
      "252/252 [==============================] - 1s 2ms/step - loss: 0.6380\n",
      "Epoch 12/20\n",
      "252/252 [==============================] - 1s 2ms/step - loss: 0.6197\n",
      "Epoch 13/20\n",
      "252/252 [==============================] - 1s 2ms/step - loss: 0.6234\n",
      "Epoch 14/20\n",
      "252/252 [==============================] - 1s 2ms/step - loss: 0.6046\n",
      "Epoch 15/20\n",
      "252/252 [==============================] - 0s 2ms/step - loss: 0.6006\n",
      "Epoch 16/20\n",
      "252/252 [==============================] - 0s 2ms/step - loss: 0.6141\n",
      "Epoch 17/20\n",
      "252/252 [==============================] - 1s 2ms/step - loss: 0.6074\n",
      "Epoch 18/20\n",
      "252/252 [==============================] - 0s 2ms/step - loss: 0.5919\n",
      "Epoch 19/20\n",
      "252/252 [==============================] - 0s 2ms/step - loss: 0.5942\n",
      "Epoch 20/20\n",
      "252/252 [==============================] - 0s 2ms/step - loss: 0.5950\n"
     ]
    }
   ],
   "source": [
    "m1.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "hist1=m1.fit(x_train_1, y_train, epochs=20, batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = m1.predict(x_train_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70.2866615537398"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err = error(y_train, pred)\n",
    "err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
